{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Acquireeasy-bot\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.19MB/s]\n",
      "d:\\Acquireeasy-bot\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raghavan Kumar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:01<00:00, 444kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 666/666 [00:00<00:00, 36.1kB/s]\n",
      "Downloading model.safetensors:  44%|████▍     | 1.44G/3.25G [01:24<01:52, 16.1MB/s]"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tokenizer \u001b[39m=\u001b[39m GPT2Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mgpt2-large\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m GPT2LMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39mgpt2-large\u001b[39;49m\u001b[39m'\u001b[39;49m , pad_token_id \u001b[39m=\u001b[39;49m tokenizer\u001b[39m.\u001b[39;49meos_token_id)\n",
      "File \u001b[1;32md:\\Acquireeasy-bot\\env\\lib\\site-packages\\transformers\\modeling_utils.py:2494\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2480\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   2481\u001b[0m     cached_file_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m   2482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcache_dir\u001b[39m\u001b[39m\"\u001b[39m: cache_dir,\n\u001b[0;32m   2483\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mforce_download\u001b[39m\u001b[39m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2492\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m: commit_hash,\n\u001b[0;32m   2493\u001b[0m     }\n\u001b[1;32m-> 2494\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcached_file_kwargs)\n\u001b[0;32m   2496\u001b[0m     \u001b[39m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m     \u001b[39m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m     \u001b[39mif\u001b[39;00m resolved_archive_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m filename \u001b[39m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[0;32m   2499\u001b[0m         \u001b[39m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Acquireeasy-bot\\env\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    414\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    418\u001b[0m         path_or_repo_id,\n\u001b[0;32m    419\u001b[0m         filename,\n\u001b[0;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    430\u001b[0m     )\n\u001b[0;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m     )\n",
      "File \u001b[1;32md:\\Acquireeasy-bot\\env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Acquireeasy-bot\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[0;32m   1362\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1364\u001b[0m     http_get(\n\u001b[0;32m   1365\u001b[0m         url_to_download,\n\u001b[0;32m   1366\u001b[0m         temp_file,\n\u001b[0;32m   1367\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1368\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m   1369\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1370\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Acquireeasy-bot\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:544\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    543\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n\u001b[1;32m--> 544\u001b[0m         temp_file\u001b[39m.\u001b[39;49mwrite(chunk)\n\u001b[0;32m    546\u001b[0m \u001b[39mif\u001b[39;00m expected_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m expected_size \u001b[39m!=\u001b[39m temp_file\u001b[39m.\u001b[39mtell():\n\u001b[0;32m    547\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConsistency check failed: file should be of size \u001b[39m\u001b[39m{\u001b[39;00mexpected_size\u001b[39m}\u001b[39;00m\u001b[39m but has size\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mtemp_file\u001b[39m.\u001b[39mtell()\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mWe are sorry for the inconvenience. Please retry download and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m pass `force_download=True, resume_download=False` as argument.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf the issue persists, please let us\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m know by opening an issue on https://github.com/huggingface/huggingface_hub.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.1776.0_x64__qbz5n2kfra8p0\\lib\\tempfile.py:474\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[39m@_functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 474\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors:  44%|████▍     | 1.44G/3.25G [01:43<01:52, 16.1MB/s]"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large') \n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large' , pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii (T. c. ʳɑtʳi ) to the same language and to \"the same person.\"\n",
      "\n",
      "The last sentence follows \"the same person\" and, in Spanish, \"the person who speaks the same language.\" However, the Spanish character for \"one\" in a pronoun is \"t\" (see English sentence).\n",
      "\n",
      "For the most part, when the pronoun is used a third time, the second or third time it is used does not affect other nouns:\n",
      "\n",
      "The last word on the list is always \"he made.\"\n",
      "\n",
      "In Latin, this occurs twice a year.\n",
      "\n",
      "The last syllable of a \"proto\" is the last letter of a letter in either case. So, the following is what \"he made\" means: \"made up of two copies of himself.\"\n",
      "\n",
      "In Spanish, this occurs twice a year.\n",
      "\n",
      "And what is used in the first case, the sentence \"he\n"
     ]
    }
   ],
   "source": [
    "sentence = 'What is Elasticsearch?' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sentence, return_tensors='pt') \n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, \n",
    "max_length = 1000, \n",
    "num_beams = 5,\n",
    "no_repeat_ngram_size = 2,\n",
    "early_stopping = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tokenizer.decode(output[0], skip_special_tokens=True )) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
